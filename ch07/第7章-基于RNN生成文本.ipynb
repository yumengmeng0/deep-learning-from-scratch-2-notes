{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 第7章 基于RNN生成文本\n",
    "\n",
    "seq2seq 是“(from) sequence to sequence”（从时序到时序）的意思，即将一个时序数\n",
    "据转换为另一个时序数据。\n",
    "\n",
    "通过组合两个 RNN，可以轻松实现 seq2seq。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.1 使用语言模型生成文本\n",
    "\n",
    "### 7.1.1 使用RNN生成文本的步骤\n",
    "\n",
    "![](../images/图7-1.上一章实现的语言模型：右图使用整体处理时序数据的Time层；左图是将其展.PNG)\n",
    "图7-1.上一章实现的语言模型：右图使用整体处理时序数据的Time层；左图是将其展开后的层结构\n",
    "\n",
    "![](../images/图7-2.语言模型输出下一个出现的单词的概率分布.PNG)\n",
    "图7-2.语言模型输出下一个出现的单词的概率分布\n",
    "\n",
    "如何生成下一个新单词呢？\n",
    "* 概率最高的单词\n",
    "* “概率性地”进行选择\n",
    "\n",
    "![](../images/图7-3.根据概率分布采样一个单词.PNG)\n",
    "图7-3.根据概率分布采样一个单词\n",
    "\n",
    "“确定性的”是指（算法的）结果是唯一确定的，是可预测的。\n",
    "“概率性的”算法则概率性地确定结果。\n",
    "\n",
    "![](../images/图7-4.重复概率分布的输出和采样.PNG)\n",
    "图7-4.重复概率分布的输出和采样\n",
    "\n",
    "\n",
    "### 7.1.2 文本生成的实现\n",
    "\n",
    "文本生成的实现。这里基于上一章实现的 Rnnlm 类（[ch06/rnnlm.py](../ch06/rnnlm.py)），来创建继承自它的 RnnlmGen 类，\n",
    "然后向这个类添加生成文本的方法。\n",
    "\n",
    "RnnlmGen 类的实现如下所示（[ch07/rnnlm_gen.py](../ch07/rnnlm_gen.py)）\n",
    "\n",
    "使用这个 RnnlmGen 类进行文本生成。这里先在完全没有学习的状态（即权重参数是随机初始值的状态）下生成文本，\n",
    "代码如下所示（[ch07/generate_text.py](../ch07/generate_text.py)）\n",
    "\n",
    "### 7.1.3 更好的文本生成\n",
    "\n",
    "（[ch07/generate_better_text.py](../ch07/generate_better_text.py)）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.2 seq2seq模型\n",
    "\n",
    "文本数据、音频数据和视频数据都是时序数据。\n",
    "将一种时序数据转换为另一种时序数据的任务，比如机器翻译、语音识别等。\n",
    "\n",
    "### 7.2.1 seq2seq的原理\n",
    "\n",
    "seq2seq 模型也称为 Encoder-Decoder 模型。顾名思义，这个模型有两\n",
    "个模块——Encoder（编码器）和 Decoder（解码器）。编码器对输入数据\n",
    "进行编码，解码器对被编码的数据进行解码。\n",
    "\n",
    "![](../images/图7-5.基于编码器和解码器进行翻译的例子.PNG)\n",
    "图7-5.基于编码器和解码器进行翻译的例子\n",
    "\n",
    "编码器首先对“吾輩は猫である”这句话进行编码，然后将编码好的信息传递给解码器，由解码器生成目标文本。\n",
    "此时，编码器编码的信息浓缩了翻译所必需的信息，解码器基于这个浓缩的信息生成目标文本。\n",
    "\n",
    "![](../images/图7-6.编码器的层结构.PNG)\n",
    "图7-6.编码器的层结构\n",
    "\n",
    "![](../images/图7-7.编码器将文本编码为固定长度的向量.PNG)\n",
    "图7-7.编码器将文本编码为固定长度的向量\n",
    "\n",
    "![](../images/图7-8.解码器的层结构.PNG)\n",
    "图7-8.解码器的层结构\n",
    "\n",
    "![](../images/图7-9.seq2seq的整体的层结构.PNG)\n",
    "图7-9.seq2seq的整体的层结构\n",
    "\n",
    "### 7.2.2 时序数据转换的简单尝试\n",
    "\n",
    "![](../images/图7-10.让seq2seq学习加法的例子.PNG)\n",
    "图7-10.让seq2seq学习加法的例子\n",
    "\n",
    "### 7.2.3 可变长的时序数据\n",
    "\n",
    "在使用批数据进行学习时，会一起处理多个样本。此时，（在我们的\n",
    "实现中）需要保证一个批次内各个样本的数据形状是一致的。\n",
    "\n",
    "在基于 mini-batch 学习可变长度的时序数据时，最简单的方法是使用\n",
    "**填充**（padding）。所谓填充，就是用无效（无意义）数据填入原始数据，从\n",
    "而使数据长度对齐。\n",
    "\n",
    "![](../images/图7-11.为了进行mini-batch学习，使用空白字符进行填充，使输入和输出的大小对齐.PNG)\n",
    "图7-11.为了进行mini-batch学习，使用空白字符进行填充，使输入和输出的大小对齐\n",
    "\n",
    "### 7.2.4 加法数据集\n",
    "\n",
    "![](../images/图7-12.加法的学习数据：空白字符（空格）用灰色的点表示.PNG)\n",
    "图7-12.加法的学习数据：空白字符（空格）用灰色的点表示\n",
    "\n",
    "专用模块（[dataset/sequence.py](../dataset/sequence.py)），这个模块有 load_data() 和 get_vocab() 两个方法\n",
    "\n",
    "load_data(file_name, seed) 读入由 file_name 指定的文本文件，并将文\n",
    "本转换为字符 ID，返回训练数据和测试数据。该方法内部设有随机数种子\n",
    "seed 以打乱数据，分割训练数据和测试数据。另外，get_vocab() 方法返回\n",
    "字符与 ID 的映射字典（实际上返回 char_to_id 和 id_to_char）。\n",
    "\n",
    "（[ch07/show_addition_dataset.py](../ch07/show_addition_dataset.py)）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.3 seq2seq的实现\n",
    "\n",
    "seq2seq 是组合了两个 RNN 的神经网络。这里我们首先将这两个 RNN\n",
    "实现为 Encoder 类和 Decoder 类，然后将这两个类组合起来，来实现 seq2seq 类。\n",
    "\n",
    "### 7.3.1 Encoder类\n",
    "\n",
    "![](../images/图7-13.Encoder类的输入输出.PNG)\n",
    "图7-13.Encoder类的输入输出\n",
    "\n",
    "![](../images/图7-14.编码器的层结构.PNG)\n",
    "图7-14.编码器的层结构\n",
    "\n",
    "如图 7-14 所示，Encoder 类由 Embedding 层和 LSTM 层组成。\n",
    "\n",
    "在编码器处理完最后一个字符后，输出 LSTM 层的隐藏状态 h。然后，这个隐藏状态 h 被传递给解码器。\n",
    "\n",
    "![](../images/图7-15.使用Time层实现编码器.PNG)\n",
    "图7-15.使用Time层实现编码器\n",
    "\n",
    "### 7.3.2 Decoder类\n",
    "\n",
    "Decoder 类的实现。如图 7-16 所示，Decoder 类接收 Encoder 类输出的 h，输出目标字符串。\n",
    "\n",
    "![](../images/图7-16.编码器和解码器.PNG)\n",
    "图7-16.编码器和解码器\n",
    "\n",
    "![](../images/图7-17.解码器的层结构（学习时）.PNG)\n",
    "图7-17.解码器的层结构（学习时）\n",
    "\n",
    "![](../images/图7-18.解码器生成字符串的步骤：通过argmax节点从Affine层的输出中选择最大值的索引（字符ID）.PNG)\n",
    "图7-18.解码器生成字符串的步骤：通过argmax节点从Affine层的输出中选择最大值的索引（字符ID）\n",
    "\n",
    "![](../images/图7-19.Decoder类的结构.PNG)\n",
    "图7-19.Decoder类的结构\n",
    "\n",
    "由图 7-19 可以看出，Decoder 类由 Time Embedding、Time LSTM 和\n",
    "Time Affine 这 3 个层构成。\n",
    "\n",
    "### 7.3.3 Seq2seq类\n",
    "\n",
    "（[ch07/seq2seq.py](../ch07/seq2seq.py)）\n",
    "\n",
    "### 7.3.4 seq2seq的评价\n",
    "\n",
    "基础神经网络的学习流程如下：\n",
    "1. 从训练数据中选择一个 mini-batch\n",
    "2. 基于 mini-batch 计算梯度\n",
    "3. 使用梯度更新权重\n",
    "\n",
    "seq2seq 的学习代码（[ch07/train_seq2seq.py](../ch07/train_seq2seq.py)）\n",
    "\n",
    "![](../images/图7-22.正确率的变化.PNG)\n",
    "图7-22.正确率的变化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.4 seq2seq的改进\n",
    "\n",
    "### 7.4.1 反转输入数据（Reverse）\n",
    "\n",
    "![](../images/图7-23.反转输入数据的例子.PNG)\n",
    "图7-23.反转输入数据的例子\n",
    "\n",
    "```python\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "# 反转数组\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "```\n",
    "\n",
    "![](../images/图7-24.seq2seq的正确率的变化：baseline是上一节的结果，reverse是反转输入数据后的结果.PNG)\n",
    "图7-24.seq2seq的正确率的变化：baseline是上一节的结果，reverse是反转输入数据后的结果\n",
    "\n",
    "为什么反转数据后，学习进展变快，精度提高了呢？虽然理论上不是很清楚，但是直观上可以认为，反转数据后梯度的传播可以更平滑。\n",
    "\n",
    "在反转输入数据后，单词之间的“平均”距离并不会发生改变。\n",
    "\n",
    "### 7.4.2 偷窥（Peeky）\n",
    "\n",
    "编码器将输入语句转换为固定长度的向量 h，这个 h集中了解码器所需的全部信息。也就是说，它是解码器唯一的信息源。\n",
    "\n",
    "![](../images/图7-25.改进前：只有最开始的LSTM层接收编码器的输出h.PNG)\n",
    "图7-25.改进前：只有最开始的LSTM层接收编码器的输出h\n",
    "\n",
    "将这个集中了重要信息的编码器的输出 h 分配给解码器的其他层。\n",
    "\n",
    "![](../images/图7-26.改进后：将编码器的输出h分配给所有时刻的LSTM层和Affine层.PNG)\n",
    "图7-26.改进后：将编码器的输出h分配给所有时刻的LSTM层和Affine层\n",
    "\n",
    "有两个向量同时被输入到了 LSTM 层和 Affine 层，这实际上表示两个向量的拼接（concatenate）。\n",
    "\n",
    "![](../images/图7-27.在Affine层的输入有两个的情况下（左图），将它们拼接起来输入Affine层（右图）.PNG)\n",
    "图7-27.在Affine层的输入有两个的情况下（左图），将它们拼接起来输入Affine层（右图）\n",
    "\n",
    "PeekyDecoder 类的实现[ch07/peeky_seq2seq.py](../ch07/peeky_seq2seq.py)\n",
    "\n",
    "![](../images/图7-28.“reverse+peeky”是进行了本节的两个改进的结.PNG)\n",
    "图7-28.“reverse+peeky”是进行了本节的两个改进的结\n",
    "\n",
    "使用 Peeky 后，网络的权重\n",
    "参数会额外地增加，计算量也会增加，所以这里的实验结果必须考虑到相应\n",
    "地增加的“负担”。另外，seq2seq 的精度会随着超参数的调整而大幅变化。\n",
    "虽然这里的结果是可靠的，但是在实际问题中，它的效果可能不稳定。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.5 seq2seq的应用\n",
    "\n",
    "* 机器翻译：将“一种语言的文本”转换为“另一种语言的文本”\n",
    "* 自动摘要：将“一个长文本”转换为“短摘要”\n",
    "* 问答系统：将“问题”转换为“答案”\n",
    "* 邮件自动回复：将“接收到的邮件文本”转换为“回复文本”\n",
    "\n",
    "### 7.5.1 聊天机器人\n",
    "\n",
    "### 7.5.2 算法学习\n",
    "\n",
    "### 7.5.3 自动图像描述\n",
    "\n",
    "将图像转换为文本的**自动图像描述**（image captioning）\n",
    "\n",
    "![](../images/图7-31.用于自动图像描述的seq2seq的网络结构示例.PNG)\n",
    "图7-31.用于自动图像描述的seq2seq的网络结构示例\n",
    "\n",
    "它和之前的网络的唯一区别在于，编码器从 LSTM 换成了 CNN（Convolutional Neural Network，卷积神经网络），而解码器仍使用与之前相同的网络。仅通过这点改变（用\n",
    "CNN 替代 LSTM），seq2seq 就可以处理图像了。\n",
    "\n",
    "图 7-31 的 CNN 使用 VGG、ResNet 等成熟网络，并使用在别的图\n",
    "像数据集（ImageNet 等）上学习好的权重，这样可以获得好的编码，\n",
    "从而生成好的文本。\n",
    "\n",
    "![](../images/图7-32.自动图像描述的例子：将图像转换为文本.PNG)\n",
    "图7-32.自动图像描述的例子：将图像转换为文本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.6 小结\n",
    "\n",
    "seq2seq 模型拼接了编码器和解码器，是组合了两个 RNN 的简单结构。\n",
    "改进 seq2seq 的两个方案——Reverse 和 Peeky。\n",
    "\n",
    "## 本章所学的内容\n",
    "\n",
    "* 基于 RNN 的语言模型可以生成新的文本\n",
    "* 在进行文本生成时，重复“输入一个单词（字符），基于模型的输出（概率分布）进行采样”这一过程\n",
    "* 通过组合两个 RNN，可以将一个时序数据转换为另一个时序数据（seq2seq）\n",
    "* 在 seq2seq 中，编码器对输入语句进行编码，解码器接收并解码这个编码信息，获得目标输出语句\n",
    "* 反转输入语句（Reverse）和将编码信息分配给解码器的多个层（Peeky）可以有效提高 seq2seq 的精度\n",
    "* seq2seq 可以用在机器翻译、聊天机器人和自动图像描述等各种各样的应用中\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
